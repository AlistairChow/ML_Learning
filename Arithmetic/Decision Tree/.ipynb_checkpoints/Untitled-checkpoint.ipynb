{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树算法（Decision Tree）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。\n",
    "> **优点**：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不想管特征数据  \n",
    "> **缺点**：可能会产生过拟合问题  \n",
    "> **使用数据类型**：数值型和标称型  \n",
    "\n",
    "相较于KNN，决策树的主要优势在于数据形式非常容易理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法流程\n",
    "1. 收集数据：可以使用任何方法\n",
    "2. 准备数据：树构造算法值适用于标称型数据，因此数值型数据必须离散化\n",
    "3. 分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期\n",
    "4. 训练算法：构造树的数据结构\n",
    "5. 测试算法：使用经验树计算错误率\n",
    "6. 使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好的理解数据的内在含义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息增益（information gain)\n",
    "划分数据集的大原则是，将无序的数据变得更加有序。我们可以有多种方法划分数据集，但是每种方法都有各自的优缺点。  \n",
    "在划分数据集之前之后信息发生的变化称为信息增益，获得信息增益最高的特征就是最好的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 熵（entropy）\n",
    "集合信息的度量方式称为香农熵或简称熵，这个名字来源于信息论之父克劳德·香农。\n",
    "熵定义为信息的期望值。如果待分类的事物可能划分在多个分类之中，则符号$x_i$的信息定义为\n",
    "$$l(x_i)=-log_2p(x_i)$$\n",
    "$p(x_i)$是选择该分类的概率。\n",
    "为了计算熵，需要计算所有类别所有可能值包含的信息期望值，公式如下\n",
    "$$H=-\\sum_{i=1}^np(x_i)log_2p(x_i)$$\n",
    "$n$是分类的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    '''\n",
    "    计算给定数据集的熵\n",
    "    '''\n",
    "    # 获取数据集示例数量\n",
    "    numEntries = len(dataSet)\n",
    "    # 构造分类标签字典\n",
    "    labelCounts = {}\n",
    "    \n",
    "    # 遍历数据集，获取分类标签数量\n",
    "    for featVec in dataSet:\n",
    "        curLable = featVec[-1]\n",
    "        if curLable not in labelCounts.keys():\n",
    "            labelCounts[curLable] = 0\n",
    "        labelCounts[curLable] += 1\n",
    "    # 遍历分类标签，计算熵\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    \n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "海洋生物数据，如下\n",
    "\n",
    "||不浮出水面是否可以生存|是否有脚蹼|属于鱼类|\n",
    "|--|--|--|--|\n",
    "|1|是|是|是|\n",
    "|2|是|是|是|\n",
    "|3|是|否|否|\n",
    "|4|否|是|否|\n",
    "|5|否|是|否|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据海洋生物数据构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算数据集的熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, labels = createDataSet()\n",
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵越大，则代表混合的数据越多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3709505944546687"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet[0][-1]='maybe' # 增加一个新的分类maybe\n",
    "calcShannonEnt(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类增加，导致熵变大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集\n",
    "分类算法除了需要测量数据集的无序程度，还需要划分数据集，度量划分数据集的无序程度，以便判断当前划分是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    '''\n",
    "    按照给定特征划分数据集\n",
    "    param dataSet: 待划分的数据集\n",
    "    param axis: 划分数据集的特征\n",
    "    param value: 需要返回的特征的值\n",
    "    '''\n",
    "    retDataSet = []\n",
    "    # 遍历数据集，返回给定特征等于特定值的示例集\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如我们要以特征“不浮出水面是否可以生存”进行划分，然后返回可以生存的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'maybe'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(dataSet, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在需要通过计算熵，找到最好的划分数据的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    '''\n",
    "    选择最好的数据划分方式\n",
    "    '''\n",
    "    # 特征值数量\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # 数据集划分前的熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    # 最优的信息增益\n",
    "    bestInfoGain = 0.0\n",
    "    # 最优的数据划分特征\n",
    "    bestFeature = -1\n",
    "    \n",
    "    # 遍历特征，对每个特征进行数据划分，找到最优信息增益的特征\n",
    "    for i in range(numFeatures):\n",
    "        # 创建唯一的特征值列表\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        # 数据划分后的熵\n",
    "        newEntropy = 0.0\n",
    "        \n",
    "        # 按照指定特征进行数据划分，并计算数据划分后的熵\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        \n",
    "        # 找到最优信息增益所对应的特征值\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        if(infoGain > bestInfoGain):\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    \n",
    "    return bestFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用海洋生物数据进行测试，发现第一次最优的数据划分特征是“不浮出水面是否可以生存”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseBestFeatureToSplit(dataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 递归构造决策树\n",
    "由于特征值可能不止一个，因此存在大于两个分支的数据集划分。划分一次后，数据将被向下传递到树分支节点，进行再次划分。因此可以采用递归的原则处理数据。  \n",
    "伪代码如下：  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if 类别相同  \n",
    "&emsp;&emsp;return 该类别  \n",
    "elif　遍历完所有特征  \n",
    "&emsp;&emsp;return 返回数量最多的类别  \n",
    "elif  \n",
    "&emsp;&emsp;寻找划分数据的最好特征  \n",
    "&emsp;&emsp;划分数据集  \n",
    "&emsp;&emsp;创建分支节点  \n",
    "&emsp;&emsp;for 每个划分的子集  \n",
    "&emsp;&emsp;&emsp;&emsp;调用函数createTree并增加返回结果到分支节点中  \n",
    "&emsp;&emsp;return 分支节点  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    '''\n",
    "    获取次数最多的分类名称\n",
    "    '''\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    \n",
    "    sortedClassCount = sorted(classCount.iteritems(),\n",
    "                             key=operator.itemgetter(1),\n",
    "                             reversed=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def createTree(dataSet, labels):\n",
    "    # 数据集的所有分类\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 类别完全相同则停止划分\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 遍历完所有特征时返回次数最多的类别\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    \n",
    "    # 选择数据划分最优特征并构建树\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    myTree = {bestFeatLabel:{}}\n",
    "    del(labels[bestFeat])\n",
    "    \n",
    "    # 划分数据集，创建分支节点，并递归分支节点\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels[:]\n",
    "        myTree[bestFeatLabel][value] = createTree(\n",
    "            splitDataSet(dataSet, bestFeat, value), subLabels)\n",
    "        \n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用海洋生物数据集进行测试。可以发现返回值是一个嵌套的字典类型。如果字典的值是数据字典，代表这是一个分支节点；如果字典的值是一个特定值，那么代表这是一个叶节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSet, labels = createDataSet()\n",
    "createTree(dataSet, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
