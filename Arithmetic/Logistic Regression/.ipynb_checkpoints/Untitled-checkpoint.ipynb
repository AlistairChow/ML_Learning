{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归（Logistic Regression）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "假设现在有一些数据点，用一条直线对这些点进行拟合（该线称为最佳拟合直线），这个拟合过程就称为回归。  \n",
    "利用逻辑回归进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法流程\n",
    "> 收集数据：采用任意方法收集数据\n",
    "> 准备数据：由于需要进行距离计算，因此要求数据类型为数值型。另外，结构化数据格式则最佳  \n",
    "> 分析数据：采用任意方法对数据进行分析  \n",
    "> 训练算法：大部分时间将用于训练，训练的目的是为了找到最佳的分类回归系数  \n",
    "> 测试算法：一旦训练步骤完成，分类将会很快  \n",
    "> 使用算法：首先，需要输入一些数据，并将其转换成对应的结构化数值；接着，基于训练好的回归系数就可以对这些数值进行简单的回归计算，判定它们属于哪个类别；在这之后，就可以在输出的类别上做一些其他分析工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于逻辑回归和Sigmoid函数的分类\n",
    "逻辑回归\n",
    "> 优点：计算代价不高，易于理解和实现  \n",
    "> 缺点：容易欠拟合，分类精度可能不高  \n",
    "> 适用数据类型：数值型和标称型数据  \n",
    "\n",
    "我们想要的函数应该是，能接受所有的输入然后预测出类别。例如，对于而分类问题，该函数应该返回0或1。具有这种性质的函数称为**海维塞德阶跃函数(Heaviside step function)**，或直接称为**单位阶跃函数**。海维塞德阶跃函数的问题在于：该函数在跳跃点上从0瞬间跳跃到1，这个瞬间跳跃过程有时很难处理。\n",
    "Sigmoid函数是一个S型曲线，其函数形式为：\n",
    "$$\\sigma(z)=\\frac{1}{1+e^{-z}}$$\n",
    "当输入z等于0时，Sigmoid函数值为0.5。随着z的增大，对应的函数值趋近于1；随着z的减小，对应的函数值趋近于0。\n",
    "https://zh.wikipedia.org/wiki/S%E5%87%BD%E6%95%B0#/media/File:Sigmoid_function_01.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于最优化方法的最佳回归系数确定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度上升法\n",
    "梯度上升法基于的思想是：要找到某函数的最大值，最好的方法是沿着该函数的梯度方向探寻。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loadDataSet():\n",
    "    '''\n",
    "    加载数据集\n",
    "    '''\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open('testSet.txt')\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def sigmoid(inX):\n",
    "    return 1.0/(1+np.exp(-inX))\n",
    "\n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    dataMatix = np.mat(dataMatIn)\n",
    "    labelMat = np.mat(classLabels).transpose()\n",
    "    m, n = np.shape(dataMatix)\n",
    "    alpha = 0.001\n",
    "    maxCycles = 500\n",
    "    weights = np.ones((n, 1))\n",
    "    \n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(dataMatix * weights)\n",
    "        error = (labelMat - h)\n",
    "        weights = weights + alpha * dataMatix.transpose() * error\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 4.12414349],\n",
       "        [ 0.48007329],\n",
       "        [-0.6168482 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArr, labelMat = loadDataSet()\n",
    "gradAscent(dataArr, labelMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
