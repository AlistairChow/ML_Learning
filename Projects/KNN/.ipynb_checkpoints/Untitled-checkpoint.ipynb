{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-近邻算法（K Nearest Neighbor, KNN）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN采用测量不同特征值之间的距离方法来进行分类。  \n",
    "KNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。  \n",
    "> **优点** ：精度高、对异常值不敏感、无数据输入假定  \n",
    "> **缺点** ：计算复杂度高、空间复杂度高  \n",
    "> **适用数据范围**： 数值型和标称型  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 收集数据\n",
    "2. 准备数据：距离计算所需要的数值，最好是结构化的数据格式\n",
    "3. 分析数据：可以适用任何方法\n",
    "4. 训练算法：此步骤不适用于KNN\n",
    "5. 测试算法：计算错误率\n",
    "6. 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对未知类别属性的数据集种的每个点依次执行以下步骤：\n",
    "1. 计算已知类别属性的数据集中的每个点与当前点之间的距离\n",
    "2. 按照距离递增次序排序\n",
    "3. 选取与当前点距离最小的k个点\n",
    "4. 确定前k个点所在类别的出现频率\n",
    "5. 返回前k个点出现频率最高的类别作为当前点的预测分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
